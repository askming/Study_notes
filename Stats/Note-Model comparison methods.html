
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Model comparison methods &#8212; Study Notes</title>
    
  <link href="../_static/css/theme.css" rel="stylesheet">
  <link href="../_static/css/index.ff1ffe594081f20da1ef19478df9384b.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-book-theme.css?digest=c3fdc42140077d1ad13ad2f1588a4309" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.be7d3bbb2ef33a8344ce.js">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/sphinx-book-theme.d59cb220de22ca1c485ebbdc042f0030.js"></script>
    <script src="https://wavedrom.com/skins/default.js"></script>
    <script src="https://wavedrom.com/wavedrom.min.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script src="https://unpkg.com/mermaid/dist/mermaid.min.js"></script>
    <script>mermaid.initialize({startOnLoad:true});</script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Monte Carlo Method" href="Note-Monte%20Carlo%20method.html" />
    <link rel="prev" title="Missing data" href="Note-Missing%20data.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../_static/logo.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Study Notes</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../intro.html">
   Study Notes Index (knowledge base structure)
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Statistics
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="Book-Analysis%20of%20Observational%20Health%20Care%20Data%20Using%20SAS.html">
   [book] Analysis of Observational Health Care Data Using SAS
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Book-Causal_inference_in_statistics_a_primer.html">
   [book] Causal inference in statistics
   <em>
    a primer
   </em>
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Book-Data_Analysis_Using_Regression_and_Multilevel_Hierarchical_Models.html">
   [book] Data Analysis Using Regression and Multilevel/Hierarchical Models
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Book-Fundamentals%20of%20Clinical%20Trials%20%284th%20edition%29.html">
   [book] Fundamentals of Clinical Trials (4th edition)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Book-Group%20Sequential%20and%20Confirmatory%20Adaptive%20Designs%20in%20Clinical%20Trials.html">
   [book] Group Sequential and Confirmatory Adaptive Designs in Clinical Trials
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Book-Regression%20Modeling%20Strategies.html">
   [book] Regression Modeling Strategies
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Note-Adaptive%20Trial%20Design.html">
   Adaptive Clinical Trial Design
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Note-Analysis%20of%20Ordinal%20Outcome.html">
   Analysis of ordinal outcome
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Note-Analysis%20of%20Stratified%20Randomization%20Trial%20Data.html">
   Why analysis of stratified randomization trial data need to account for the stratification factors?
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Note-Association%20vs.%20Prediction%20vs.%20Causation.html">
   Association vs. Prediction vs. Causation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Note-Baseline%20Adaptive%20Randomization.html">
   Baseline adaptive randomization
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Note-Bayesian%20optimization.html">
   Exploring Bayesian Optimization
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Note-Causal%20inference%20general.html">
   Causal Inference General Study Notes
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Note-Competing_Risk_Regression.html">
   Competing risk models
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Note-Correlated%20Data%20Analysis.html">
   Correlated/Longitudinal Data Analysis
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Note-Cox_PH_model.html">
   ​Cox PH model
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Note-Dirichlet%20process.html">
   Dirichlet process
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Note-FDA%20guidances%20for%20industry.html">
   Notes on FDA Guidances for Industry
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Note-Gaussian%20process.html">
   Gaussain Process
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Note-Group_Sequential_Trial_Design.html">
   Notes on Group Sequential Trial Design​
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Note-ICH%20guidelines.html">
   Notes on ICH guidelines​
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Note-MDD%20%26%20Effect%20size.html">
   Power,
   <strong>
    MDD
   </strong>
   /
   <strong>
    E
   </strong>
   (minimum detectable difference/effect), and
   <strong>
    Effect size
   </strong>
   in clinical trials
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Note-Meta-Analysis.html">
   Meta-analysis​
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Note-Missing%20data.html">
   Missing data
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   Model comparison methods
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Note-Monte%20Carlo%20method.html">
   Monte Carlo Method
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Note-Multicolinearity.html">
   Multicolinearity
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Note-Multiplicity%20in%20Clinical%20Trials.html">
   Multiplicity in Clinical Trials
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Note-Non-inferiority%20equivalence%20superiority%20test.html">
   Non-inferiority/equivalence/superiority test basics
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Note-Observational%20study%20design.html">
   Observational study design
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Note-Propensity%20score%20methods.html">
   Propensity Score Methods &amp; Implementation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Note-Quantile%20regression.html">
   Quantile regression
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Note-Sample_size_calculation_with_WMW_test.html">
   Sample size calculation for the Wilcoxon-Mann-Whitney test adjusting for ties
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Note-Survival_Analysis.html">
   Survival Analysis
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Statistical computing
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../Stats_Comp/Note-How%20R%20searches%20and%20finds%20stuff.html">
   How R searches and finds stuff
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Stats_Comp/Note-R%20notes.html">
   R study notes/tips
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Stats_Comp/Note-googleVis.html">
   Google R package googleVis
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Stats_Comp/Note-matplotlib.html">
   Notes on
   <code class="docutils literal notranslate">
    <span class="pre">
     matplotlib
    </span>
   </code>
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  DS/ML
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../DS_ML/Book-Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow.html">
   [book] Hands-On Machine Learning with Scikit-Learn and TensorFlow
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../DS_ML/Book-Python%20Data%20Science%20Handbook.html">
   [book] Python Data Science Handbook
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../DS_ML/Note-Boosting.html">
   Boosting
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../DS_ML/Note-Cluster%20analysis.html">
   Cluster analysis
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../DS_ML/Note-Machine%20Learning%20%28General%29.html">
   ​Machine Learning (General)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../DS_ML/Note-Naive%20Bayes.html">
   Naive Bayes
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../DS_ML/Note-Stochasitic%20Gradient%20Descent.html">
   Stochastic Gradient Decent (SGD)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../DS_ML/Note-Tree%2C%20Random%20Forest%20%28Bagging%29.html">
   Tree/Random Forest (Bagging)
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Computer science
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../CS/Note-HTML%20basics.html">
   HTML Basics
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../CS/Note-Hard%20SQL%20interview%20questions.html">
   Hard Data Analyst SQL Interview Questions
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../CS/Note-Inside%20look%20at%20modern%20web%20browser.html">
   Inside look at modern web browser
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../CS/Note-Learning%20React.html">
   Learning React
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../CS/Note-Learning%20Rust.html">
   Learning Rust
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../CS/Note-Modern%20JS%20explained.html">
   Modern JavaScript Explained
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../CS/Note-SQL%20Study%20Notes.html">
   SQL study notes
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../CS/Note-git%20and%20github.html">
   git and github
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Miscellaneous
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../Miscellaneous/Miscellaneous%20Notes.html">
   Miscellaneous Study Notes
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Miscellaneous/Phamaceutical%20development.html">
   Pharmacedutical development
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Miscellaneous/Sim-Coin%20flip.html">
   :bulb: Q: fair coin, # of flips to get two consecutive side (H or T)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Miscellaneous/Sim-Generate%20random%20number%20between%201%20to%207.html">
   Generate random number 1 to 7 using a fair dice
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../_sources/Stats/Note-Model comparison methods.md"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.md</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
                onclick="printPdf(this)" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/askming/study_notes"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        <a class="issues-button"
            href="https://github.com/askming/study_notes/issues/new?title=Issue%20on%20page%20%2FStats/Note-Model comparison methods.html&body=Your%20issue%20content%20here."><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Open an issue"><i class="fas fa-lightbulb"></i>open issue</button></a>
        
    </div>
</div>

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show noprint">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id1">
   Model Comparison Methods
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#general-background">
     General background
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#notation-and-definition">
     Notation and definition
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#goodness-of-fit-maximized-likelihood">
     Goodness-of-fit (maximized likelihood)
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#a-good-fit-can-be-insufficient-and-misleading">
       A good fit can be insufficient and misleading
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#model-complexity">
     Model complexity
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#generalizability">
     Generalizability
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#model-comparions-methods">
     Model comparions methods
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#measures-of-generalizability">
       Measures of generalizability
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#aic-bic-and-mdl">
       AIC, BIC, and MDL
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#cross-validation-cv">
       Cross-validation (CV)
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#bayesian-model-selection-bms">
       Bayesian model selection (BMS)
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#relation-to-generalized-likelihood-ratio-test-glrt">
       Relation to generalized likelihood ratio test (GLRT)
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#comments-for-real-work">
     Comments for real work
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#bias-variance-trade-off">
   Bias-variance trade-off
  </a>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Model comparison methods</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id1">
   Model Comparison Methods
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#general-background">
     General background
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#notation-and-definition">
     Notation and definition
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#goodness-of-fit-maximized-likelihood">
     Goodness-of-fit (maximized likelihood)
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#a-good-fit-can-be-insufficient-and-misleading">
       A good fit can be insufficient and misleading
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#model-complexity">
     Model complexity
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#generalizability">
     Generalizability
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#model-comparions-methods">
     Model comparions methods
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#measures-of-generalizability">
       Measures of generalizability
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#aic-bic-and-mdl">
       AIC, BIC, and MDL
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#cross-validation-cv">
       Cross-validation (CV)
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#bayesian-model-selection-bms">
       Bayesian model selection (BMS)
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#relation-to-generalized-likelihood-ratio-test-glrt">
       Relation to generalized likelihood ratio test (GLRT)
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#comments-for-real-work">
     Comments for real work
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#bias-variance-trade-off">
   Bias-variance trade-off
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            
              <div>
                
  <div class="tex2jax_ignore mathjax_ignore section" id="model-comparison-methods">
<h1>Model comparison methods<a class="headerlink" href="#model-comparison-methods" title="Permalink to this headline">¶</a></h1>
<div class="section" id="id1">
<h2>Model Comparison Methods<a class="headerlink" href="#id1" title="Permalink to this headline">¶</a></h2>
<div class="section" id="general-background">
<h3>General background<a class="headerlink" href="#general-background" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>A list of criteria that are thought to be important for model comparison that have been proposed including:</p>
<ul>
<li><p>falsifiability</p></li>
<li><p>explanatory adequacy</p></li>
<li><p>interpretability</p></li>
<li><p>faithfulness</p></li>
<li><p>:star: <strong>goodness of fit</strong></p></li>
<li><p>:star: <strong>complexity or simplicity</strong></p></li>
<li><p>:star: <strong>generalizability</strong></p></li>
</ul>
</li>
<li><p>Modern statistical approaches to model comparison consider only the last three (goodness of fit, complexity, and generalizability).</p>
<ul>
<li><p>The goal of modeling is to identify the model that generated the data.</p></li>
<li><p>Challenges:
a) information in the data sample itself is frequently insufficient to narrow the choices down to a single model.
b) data are inevitably confounded by random noise (sampling error, measurement error, etc.).</p></li>
<li><p>Model selection is an inference game, with selection methods differing in their rules of play.</p></li>
</ul>
</li>
</ul>
</div>
<div class="section" id="notation-and-definition">
<h3>Notation and definition<a class="headerlink" href="#notation-and-definition" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>Formally, a model is defined as a parametric family of probability distributions. Each distribution is indexed by the model’s parameter vector <span class="math notranslate nohighlight">\({\boldsymbol w} = (w_1,\cdots,w_k)\)</span> and corresponds to a population.</p></li>
<li><p>The <em>probability (density) function</em>, denoted by <span class="math notranslate nohighlight">\(f({\boldsymbol y}|{\boldsymbol w})\)</span>, specifies the probability of observing data <span class="math notranslate nohighlight">\({\boldsymbol y}\)</span> given the parameter <span class="math notranslate nohighlight">\({\boldsymbol w}\)</span>.</p></li>
<li><p>Given the fixed data vector <span class="math notranslate nohighlight">\({\boldsymbol y}\)</span>, <span class="math notranslate nohighlight">\(f({\boldsymbol y|w})\)</span> becomes a function of <span class="math notranslate nohighlight">\({\boldsymbol w}\)</span> and is called the <em>likelihood function</em> denoted by <span class="math notranslate nohighlight">\({\boldsymbol L(w)}\)</span>.</p></li>
<li><p>Given a data sample, a model’s descriptive adequacy is assessed by finding parameter values of the model that best fit the data in some defined sense. This procedure, called <em>parameter estimation</em>, is carried out by seeking the parameter vector <span class="math notranslate nohighlight">\({\boldsymbol w}^*\)</span> that maximizes the likelihood function <span class="math notranslate nohighlight">\(L({\boldsymbol w})\)</span> given the observed data vector <span class="math notranslate nohighlight">\({\boldsymbol y}\)</span> <span class="math notranslate nohighlight">\(-\)</span> a procedure known as <em>maximum likelihood estimation</em>.</p></li>
</ul>
</div>
<div class="section" id="goodness-of-fit-maximized-likelihood">
<h3>Goodness-of-fit (maximized likelihood)<a class="headerlink" href="#goodness-of-fit-maximized-likelihood" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>The resulting maximized likelihood (ML) value, <span class="math notranslate nohighlight">\(L({\boldsymbol w}^*)\)</span>, defines a measure of the model’s <em>goodness of fit</em>, which represents a model’s ability to fit a particular set of observed data.</p></li>
<li><p>Other examples of goodness-of-fit measures include the <em>minimized sum of squared errors</em> (<strong>SSE</strong>) between a model’s predictions and observations, the proportion variance accounted for or otherwise known as the <em>coefficient of determination</em> <span class="math notranslate nohighlight">\(r^2\)</span>, and the <em>mean squared error</em> (<strong>MSE</strong>) defined as the square root of SSE divided by the number of observations.</p></li>
<li><p>ML is a standard measure of goodness of fit, most widely used in statistics, and all of the model comparison methods discussed in the present chapter were developed using ML.</p></li>
</ul>
<div class="section" id="a-good-fit-can-be-insufficient-and-misleading">
<h4>A good fit can be insufficient and misleading<a class="headerlink" href="#a-good-fit-can-be-insufficient-and-misleading" title="Permalink to this headline">¶</a></h4>
<div class="math notranslate nohighlight">
\[\text{goodness of fit = fit to regularity + fit to noise}\]</div>
<ul class="simple">
<li><p>Among a set of models under comparison, the scientist chooses the model that provides the best fit (i.e., highest ML value) to the observed data. The justification for this choice may be that the model best fitting the data is the one that does a better job than its rivals of capturing the underlying regularity.</p></li>
<li><p>Such reasoning can be unfounded because a model can produce a good fit for reasons that have nothing to do with its ability to approximate the regularity of interest.</p></li>
<li><p>Selecting among models using a goodness-of-fit measure would make sense if data were <em>free of noise</em>. In reality, however, data are not “pure” reflections of the population of interest.</p></li>
<li><p>Any goodness-of-fit measure contains a contribution from the model’s ability to fit random error as well as its ability to approximate the underlying regularity. The problem is that both quantities are unknown because when fitting a data set, we obtain the overall value of their sum, that is, a single goodness of fit.</p></li>
</ul>
</div>
</div>
<div class="section" id="model-complexity">
<h3>Model complexity<a class="headerlink" href="#model-complexity" title="Permalink to this headline">¶</a></h3>
<p><img alt="e8f0ce9c.png" src="https://raw.githubusercontent.com/askming/picgo/master/e8f0ce9c_20200625130118.png" /></p>
<ul class="simple">
<li><p>A model’s ability to fit random noise is closely correlated with the <em>complexity</em> of the model.</p></li>
<li><p>Complexity (or flexibility) refers to the property of a model that enables it to fit diverse patterns of data.</p></li>
<li><p>A model with many parameters is more complex than a model with few parameters. Also, two models with the same number of parameters but different forms of the model equation (e.g., <span class="math notranslate nohighlight">\(y = w_1x + w_2 \text{ and } y = w_1x^{w_2}\)</span>) can differ in their complexity.</p></li>
<li><p>Generally speaking, the more complex the model, the more easily it can absorb random noise, thus increasing its fit to the data without necessarily increasing its fit to the regularity.</p></li>
<li><p>In fact one can always improve goodness of fit by increasing model complexity, such as adding more parameters.</p></li>
</ul>
</div>
<div class="section" id="generalizability">
<h3>Generalizability<a class="headerlink" href="#generalizability" title="Permalink to this headline">¶</a></h3>
<ul>
<li><p>A model’s ability to fit the regularity in the data, represented by the first term on the right-hand side of the equation (1), defines its <em>generalizability</em>.</p></li>
<li><p>Generalizability, or predictive accuracy, refers to how well a model predicts the statistical properties of future, as yet unseen, samples from a replication of the experiment that generated the current data sample.</p></li>
<li><p>Statistically speaking, generalizability is defined in terms of a <em>discrepancy function</em> that measures the degree of approximation or dissimilarity between two probability distributions (Linhart &amp; Zucchini, 1986).</p></li>
<li><p>When a model is evaluated against its competitors, the goal should be not to assess how much better it fits a single data sample, but how well it captures the process that generated the data.</p>
<div class="math notranslate nohighlight">
\[\text{Generalizability} = E_T[D(f_T, f_M)]=\int D[f_T, f_M({\boldsymbol w^*(Y)})]f_T({\boldsymbol y})d{\boldsymbol y}\]</div>
<p>where <span class="math notranslate nohighlight">\(D(f, g)\)</span> is the discrepancy function between two distributions <span class="math notranslate nohighlight">\(f\)</span> and <span class="math notranslate nohighlight">\(g\)</span>; the less one probability distribution approximates the other, the larger value of <span class="math notranslate nohighlight">\(D(f, g)\)</span>.</p>
</li>
<li><p>Generalizability is a mean discrepancy between the true model and the model of interest, averaged across all data that could possibly be observed under the true model.</p></li>
<li><p>Generalizability increases positively with complexity only up to the point where the model is optimally complex to capture the regularities in the data. Any additional complexity beyond this point will cause generalizability to diminish as the model begins to <strong>over-fit</strong>
the data by absorbing random noise.</p></li>
<li><p>In short, a model must be sufficiently complex to capture the underlying regularity yet not too complex to cause it to over-fit the data and thus lose generalizability.</p></li>
<li><p>To reiterate, in model comparison, one would like to choose the model, among a set of competing models, that maximizes generalizability. Unfortunately, generalizability is not directly observable because noise always distorts the regularity of interest.</p></li>
<li><p>Generalizability, therefore, must be estimated from a data sample. It is achieved by weighting a model\textquoteright s goodness of fit relative to its complexity.</p></li>
</ul>
</div>
<div class="section" id="model-comparions-methods">
<h3>Model comparions methods<a class="headerlink" href="#model-comparions-methods" title="Permalink to this headline">¶</a></h3>
<div class="section" id="measures-of-generalizability">
<h4>Measures of generalizability<a class="headerlink" href="#measures-of-generalizability" title="Permalink to this headline">¶</a></h4>
<ul>
<li><p><strong>AIC</strong>: (Akaike, 1973; Bozdogan, 2000): Akaike Information Criterion</p></li>
<li><p><strong>BIC</strong>: (Schwarz, 1978): Bayesian Information Criterion</p></li>
<li><p><strong>MDL</strong>: Minimum Description Length; Rissanen, 1983, 1996; Grunwald, 200; Hanse &amp; Yu, 2001)</p></li>
<li><p><strong>CV</strong>: cross-validation; (Stone 1974; Browne, 2000)</p></li>
<li><p><strong>BMS</strong>: Bayesian model selection; (Kass &amp; Raftery, 1995; Wasserman, 2000)</p>
<div class="math notranslate nohighlight">
\[AIC=-2\ln L({\boldsymbol w}^*)+2k\]</div>
<div class="math notranslate nohighlight">
\[BIC=-2\ln L({\boldsymbol w}^*)+k\ln(n)\]</div>
<div class="math notranslate nohighlight">
\[MDL=-\ln L({\boldsymbol w}^*)+\frac{k}{2}\ln\left(\frac{n}{2\pi}\right)+\ln\int\sqrt{|I({\boldsymbol w})|}d{\boldsymbol w}\]</div>
<div class="math notranslate nohighlight">
\[CV=-\ln f({\boldsymbol y}_{val}|{\boldsymbol w}^*({\boldsymbol y}_{cal}))\]</div>
<div class="math notranslate nohighlight">
\[BMS=-\ln\int L({\boldsymbol w})\pi({\boldsymbol w})d{\boldsymbol w}\]</div>
<p>where</p>
<div class="math notranslate nohighlight">
\[L({\boldsymbol w}^*)\text{ is the natrual logarithm of the maximized likelihood};\]</div>
<div class="math notranslate nohighlight">
\[k \text{ is the number of parameter in the model};\]</div>
<div class="math notranslate nohighlight">
\[n \text{ is the sample size};\]</div>
<div class="math notranslate nohighlight">
\[\pi({\boldsymbol w})\text{ is the parameter prior density};\]</div>
<div class="math notranslate nohighlight">
\[I({\boldsymbol w})\text{ is the Fisher information matrix}.\]</div>
<p>These comparison methods prescribe that the model minimizing the given criterion should be preferred.</p>
</li>
<li><p>Among the five comparison methods discussed above, BMS and MDL represent state-of-the-art techniques that will generally perform more accurately across a range of modeling situations than the other three criteria (AIC, BIC, CV).</p></li>
<li><p>The latter three are attractive given their ease of use, and are likely to perform adequately under certain circumstances. In particular, if the models being compared <strong>do differ in number of parameters</strong> and further, <strong>sample size is sufficiently large</strong>, then one may be able to use AIC or BIC with confidence instead of the more sophisticated BMS and MDL.</p></li>
</ul>
</div>
<div class="section" id="aic-bic-and-mdl">
<h4>AIC, BIC, and MDL<a class="headerlink" href="#aic-bic-and-mdl" title="Permalink to this headline">¶</a></h4>
<ul class="simple">
<li><p>For these three, the first term represents a lack of fit measure and
the remaining terms represent a model complexity measure.</p></li>
<li><p>Each criterion defines complexity differently:</p>
<ul>
<li><p>AIC <span class="math notranslate nohighlight">\(-\)</span> # of parameters;</p></li>
<li><p>BIC <span class="math notranslate nohighlight">\(-\)</span> # of parameters + sample size;</p></li>
<li><p>MDL <span class="math notranslate nohighlight">\(-\)</span> first two terms are similar to what BIC has, the additional last term accounts for the effect of complexity due to functional form (which is reflected through the Fisher informtion matrix <span class="math notranslate nohighlight">\(I({\boldsymbol w})\)</span><a class="footnote-reference brackets" href="#mdl" id="id2">1</a></p></li>
</ul>
</li>
<li><p><strong>AIC</strong> was derived as a <em>large sample approximation</em> of the discrepancy between the true model and the fitted model in which the discrepancy is measured by the <em>Kullback-Leiber distance</em> (Kullback &amp; Leibler, 1951). AIC purports to select the model, among a set of candidate models, that is closest to the truth in the Kullback-Leibler sense.</p></li>
<li><p><strong>BIC</strong> has its origin in Bayesian statistics and seeks the model that is <em>“most likely ” to have generated the data in the Bayesian sense</em>. BIC can be seen as a large sample approximation of a quantity related to BMS.</p></li>
<li><p><strong>MDL</strong>: originated from algorithmic coding theory in computer science. The goal of MDL is to select the model that provides <em>the shortest description of the data in bits</em>. The more the model is able to compress the data by extracting the regularities or patterns in it, the better the model’s generalizability because these uncovered regularities can then be used to predict accurately future data.</p></li>
<li><p>Given this additional sensitivity, MDL is expected to perform more accurately than its two competitors. The price to pay for MDL’s superior performance is the computational challenge in its calculation; the evaluation of the integral term generally requires use of numerical integration techniques.</p></li>
</ul>
</div>
<div class="section" id="cross-validation-cv">
<h4>Cross-validation (CV)<a class="headerlink" href="#cross-validation-cv" title="Permalink to this headline">¶</a></h4>
<ul class="simple">
<li><p>CV is a sampling-based method in which generalizability is estimated directly from the data without an explicit consideration of model complexity.</p></li>
<li><p>The method works as follows.</p>
<ul>
<li><p>First, the observed data are split into two sub-samples of equal size.</p></li>
<li><p>We then fit the model of interest to the first, <em>calibration sample</em> (<span class="math notranslate nohighlight">\({\boldsymbol y}_{cal}\)</span>) and find the best-fitting parameter values, denoted by <span class="math notranslate nohighlight">\({\boldsymbol w}^*({\boldsymbol y}_{cal})\)</span>.</p></li>
<li><p>With these values fixed, the model is fitted to the second, <em>validation sample</em> (<span class="math notranslate nohighlight">\({\boldsymbol y}_{val}\)</span>). The resulting fit of the model to the validation data <span class="math notranslate nohighlight">\({\boldsymbol y}_{val}\)</span> defines the model’s generalizability estimate.</p></li>
</ul>
</li>
<li><p>CV’s ease of use is offset by the unreliability of its generalizability estimate, especially for small sample sizes.</p></li>
<li><p>Unlike AIC and BIC, CV <strong>takes</strong> into account the functional form effects of complexity, although the implicit nature of CV makes it difficult to discern how this is achieved.</p></li>
</ul>
</div>
<div class="section" id="bayesian-model-selection-bms">
<h4>Bayesian model selection (BMS)<a class="headerlink" href="#bayesian-model-selection-bms" title="Permalink to this headline">¶</a></h4>
<ul class="simple">
<li><p>BMS, a sharper version of BIC, is defined as the <em>minus marginal likelihood</em>.</p></li>
<li><p>The <em>marginal likelihood</em> is the probability of the observed data given the model, averaged over the entire range of the parameter vector and weighted by the parameter prior density <span class="math notranslate nohighlight">\(\pi({\boldsymbol w})\)</span>. As such, BMS aims to select the model with the <em>highest mean likelihood of the data</em>.</p></li>
<li><p>The often cited <em>Bayes factor}</em> (Kass &amp; Raftery, 1995) is a ratio of marginal likelihoods between a pair of models being compared.</p></li>
<li><p>BMS does not yield an explicit measure of complexity though complexity is taken into account and is hidden in the integral. It is through the integral that the functional form dimension of complexity, as well as the number of parameters and the sample size, is reflected.</p></li>
<li><p>It is also the integral that makes it non-trivial to implement BMS.</p></li>
</ul>
</div>
<div class="section" id="relation-to-generalized-likelihood-ratio-test-glrt">
<h4>Relation to generalized likelihood ratio test (GLRT)<a class="headerlink" href="#relation-to-generalized-likelihood-ratio-test-glrt" title="Permalink to this headline">¶</a></h4>
<ul>
<li><p>Although the generalized likelihood ratio test (GLRT) is often used to test the adequacy of a model in the context of another model, it is not an appropriate method for model comparison.</p></li>
<li><p>The GLRT is definded as</p>
<div class="math notranslate nohighlight">
\[G^2=-2\ln \frac{ML_0}{ML_a}\sim \chi^2_p \text{ under null}\]</div>
<p>where <span class="math notranslate nohighlight">\(\frac{ML_0}{ML_a}\)</span> is the ratio of the maximized likelihoods of two nested models, model null is nested within model alternative and <span class="math notranslate nohighlight">\(p\)</span> is the difference of number of parameters in two models under comparison.</p>
</li>
<li><p>When the null hypothesis is retained (i.e., the p-value does not exceed the alpha level), the conclusion is that the reduced model null provides a sufficiently good fit to the observed data and therefore the extra parameters of the full model alternative unnecessary. If the null hypothesis is rejected, one concludes that model null is inadequate and the extra parameters are necessary to account for the observed data.</p></li>
<li><p>Several crucial differences between GLRT and the five model comparison methods:</p>
<ul class="simple">
<li><p>First, GLRT does not assess generalizability, which is the goal of model comparison. Rather, it is a hypothesis testing method that simply judges descriptive adequacy of a given model. Even if the null hypothesis is retained under GLRT, the result does not necessarily indicate that model null is more likely to be correct or generalize better than
model alternative, or vice versa.</p></li>
<li><p>Second, GLRT requires the nestedness assumption hold of the two models <em>being tested</em>. In contrast, no such assumptions is required for the five comparison methods, making them much more versatile.</p></li>
<li><p>Third, GLRT was developed in the context of linear regression models with normally-distributed error, further restricting its use.</p></li>
<li><p>GLRT is also inappropriate for testing non-linear models and models with non-normal error. Again, no such restrictions are imposed on the preceding model comparison methods.</p></li>
</ul>
</li>
</ul>
</div>
</div>
<div class="section" id="comments-for-real-work">
<h3>Comments for real work<a class="headerlink" href="#comments-for-real-work" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>A good method should be able to identify the true model (i.e., the one that generated the data) 100% of the time. Any deviations from perfect recovery reveal a bias in the selection method.</p></li>
<li><p>It is importance to account for all relevant dimensions of complexity in model comparison. When comparing two models that have same number of parameters but different functional formats, methods only accout for number of parameters, like AIC, may be less favorable to those also account for the functional form like MDL.</p></li>
<li><p>Model comparison is an inference problem. The quality of the inference depends strongly on the characteristics of the data (e.g., sample size, experimental design, type of random error) and the models themselves (e.g., model equation, parameters, nested vs non-nested). For this reason, it is unreasonable to expect a selection method to perform
perfectly all the time.</p></li>
<li><p>When using any of these selection methods, we advise that the results be interpreted in relation to the other criteria important in model selection</p></li>
<li><p>They are not the arbiters of truth. Like any such tool, they are blind to the quality of the data and the plausibility of the models under consideration.</p></li>
</ul>
</div>
</div>
<hr class="docutils" />
<div class="section" id="bias-variance-trade-off">
<h2>Bias-variance trade-off<a class="headerlink" href="#bias-variance-trade-off" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>Common question for data science interviews</p></li>
<li><p>“Bias” and “variance” are two ways of looking at the same thing. (“Bias” is conditional, “variance” is unconditional.) <a class="footnote-reference brackets" href="#bv-trade-off-gelman" id="id3">2</a></p></li>
</ul>
<hr class="footnotes docutils" />
<dl class="footnote brackets">
<dt class="label" id="mdl"><span class="brackets"><a class="fn-backref" href="#id2">1</a></span></dt>
<dd><p>To grasp this, note that the matrix <span class="math notranslate nohighlight">\(I({\boldsymbol w})\)</span> is defined in terms of the second derivative of the log-likelihood function <span class="math notranslate nohighlight">\(\ln L({\boldsymbol w})\)</span>, the value of which depends upon the form of the model equation,for instance, whether <span class="math notranslate nohighlight">\(y=w_1x+w_2 \text{ or } y=w_1x^{w_2}\)</span></p>
</dd>
<dt class="label" id="bv-trade-off-gelman"><span class="brackets"><a class="fn-backref" href="#id3">2</a></span></dt>
<dd><p><a class="reference external" href="https://statmodeling.stat.columbia.edu/2017/03/18/noise-and-bias/">“Bias” and “variance” are two ways of looking at the same thing. (“Bias” is conditional, “variance” is unconditional.)</a></p>
</dd>
</dl>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./Stats"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>
    <script type="text/javascript">
        function init() {
            WaveDrom.ProcessAll();
        }
        window.onload = init;
    </script>

              </div>
              
            
                <!-- Previous / next buttons -->
<div class='prev-next-area'> 
    <a class='left-prev' id="prev-link" href="Note-Missing%20data.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">Missing data</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="Note-Monte%20Carlo%20method.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Monte Carlo Method</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            
        </div>
    </div>
    <footer class="footer">
  <p>
    
      By Ming Yang<br/>
    
        &copy; Copyright 2022.<br/>
  </p>
</footer>
</main>


      </div>
    </div>
  
  <script src="../_static/js/index.be7d3bbb2ef33a8344ce.js"></script>

  </body>
</html>