
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Correlated/Longitudinal Data Analysis &#8212; Study Notes</title>
    
  <link href="../_static/css/theme.css" rel="stylesheet">
  <link href="../_static/css/index.ff1ffe594081f20da1ef19478df9384b.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-book-theme.css?digest=c3fdc42140077d1ad13ad2f1588a4309" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.be7d3bbb2ef33a8344ce.js">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/sphinx-book-theme.d59cb220de22ca1c485ebbdc042f0030.js"></script>
    <script src="https://wavedrom.com/skins/default.js"></script>
    <script src="https://wavedrom.com/wavedrom.min.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script async="async" src="https://unpkg.com/thebe@0.5.1/lib/index.js"></script>
    <script>
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <script src="https://unpkg.com/mermaid/dist/mermaid.min.js"></script>
    <script>mermaid.initialize({startOnLoad:true});</script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="​Cox PH model" href="Note-Cox_PH_model.html" />
    <link rel="prev" title="Competing risk models" href="Note-Competing_Risk_Regression.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../_static/logo.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Study Notes</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../intro.html">
   Study Notes Index (knowledge base structure)
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Statistics
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="Book-Analysis%20of%20Observational%20Health%20Care%20Data%20Using%20SAS.html">
   [book] Analysis of Observational Health Care Data Using SAS
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Book-Causal%20inference%20in%20statistics%20a%20primer.html">
   [book] Causal inference in statistics
   <em>
    a primer
   </em>
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Book-Data%20Analysis%20Using%20Regression%20and%20Multilevel%20Hierarchical%20Models.html">
   [book] Data Analysis Using Regression and Multilevel/Hierarchical Models
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Book-Fundamentals%20of%20Clinical%20Trials%20%284th%20edition%29.html">
   [book] Fundamentals of Clinical Trials (4th edition)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Book-Group%20Sequential%20and%20Confirmatory%20Adaptive%20Designs%20in%20Clinical%20Trials.html">
   [book] Group Sequential and Confirmatory Adaptive Designs in Clinical Trials
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Book-Regression%20Modeling%20Strategies.html">
   [book] Regression Modeling Strategies
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Note-Adaptive%20Trial%20Design.html">
   Adaptive Clinical Trial Design
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Note-Analysis%20of%20Ordinal%20Outcome.html">
   Analysis of ordinal outcome
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Note-Analysis%20of%20Stratified%20Randomization%20Trial%20Data.html">
   Why analysis of stratified randomization trial data need to account for the stratification factors?
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Note-Association%20vs.%20Prediction%20vs.%20Causation.html">
   Association vs. Prediction vs. Causation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Note-Baseline%20Adaptive%20Randomization.html">
   Baseline adaptive randomization
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Note-Competing_Risk_Regression.html">
   Competing risk models
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   Correlated/Longitudinal Data Analysis
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Note-Cox_PH_model.html">
   ​Cox PH model
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Note-FDA%20guidances%20for%20industry.html">
   Notes on FDA Guidances for Industry
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Note-Group_Sequential_Trial_Design.html">
   Notes on Group Sequential Trial Design​
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Note-ICH%20guidelines.html">
   Notes on ICH guidelines​
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Note-MDD%20%26%20Effect%20size.html">
   Power,
   <strong>
    MDD
   </strong>
   /
   <strong>
    E
   </strong>
   (minimum detectable difference/effect), and
   <strong>
    Effect size
   </strong>
   in clinical trials
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Note-Monte%20Carlo%20method.html">
   Monte Carlo Method
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Note-Multiplicity%20in%20Clinical%20Trials.html">
   Multiplicity in Clinical Trials
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Note-Quantile%20regression.html">
   Quantile regression
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Note-Sample%20size%20calculation%20with%20WMW%20test.html">
   Sample size calculation for the Wilcoxon-Mann-Whitney test adjusting for ties
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Note-Survival_Analysis.html">
   Survival Analysis
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Statistical computing
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../Stats_Comp/How%20R%20searches%20and%20finds%20stuff.html">
   How R searches and finds stuff
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Stats_Comp/Note-matplotlib.html">
   Notes on
   <code class="docutils literal notranslate">
    <span class="pre">
     matplotlib
    </span>
   </code>
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  DS/ML
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../DS_ML/Book-Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow.html">
   [book] Hands-On Machine Learning with Scikit-Learn and TensorFlow
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../DS_ML/Book-Python%20Data%20Science%20Handbook.html">
   [book] Python Data Science Handbook
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../DS_ML/Note-Boosting.html">
   Boosting
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../DS_ML/Note-Cluster%20analysis.html">
   Cluster analysis
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../DS_ML/Note-Machine%20Learning%20%28General%29.html">
   ​Machine Learning (General)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../DS_ML/Note-Naive%20Bayes.html">
   Naive Bayes
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../DS_ML/Note-Stochasitic%20Gradient%20Descent.html">
   Stochastic Gradient Decent (SGD)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../DS_ML/Note-Tree%2C%20Random%20Forest%20%28Bagging%29.html">
   Tree/Random Forest (Bagging)
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Computer science
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../CS/Note-Learning%20React.html">
   Learning React
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../CS/Note-SQL%20Study%20Notes.html">
   SQL study notes
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Miscellaneous
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../Miscellaneous/Miscellaneous%20Notes.html">
   Miscellaneous Study Notes
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Miscellaneous/Phamaceutical%20development.html">
   Pharmacedutical development
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../_sources/Stats/Note-Correlated Data Analysis.md"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.md</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
                onclick="printPdf(this)" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/askming/study_notes"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        <a class="issues-button"
            href="https://github.com/askming/study_notes/issues/new?title=Issue%20on%20page%20%2FStats/Note-Correlated Data Analysis.html&body=Your%20issue%20content%20here."><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Open an issue"><i class="fas fa-lightbulb"></i>open issue</button></a>
        
    </div>
</div>

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show noprint">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#cross-sectional-vs-longitudinal-data">
   Cross-sectional vs longitudinal data
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#graphic-representation-of-longitudinal-data">
   Graphic representation of longitudinal data
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#y-against-time">
     Y against Time
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#y-against-x">
     Y against X​
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#fitting-smooth-curves">
     Fitting smooth curves
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#kernel-estimation">
       Kernel estimation
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#smoothing-spline">
       Smoothing spline
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#loess">
       Loess
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#exploring-correlation-structure">
     Exploring correlation structure
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#linear-model-for-correlated-data">
   Linear model for correlated data
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#random-effect-model-conditional-model">
     Random effect model (conditional model)
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#marginal-model-population-average">
     Marginal model (population average)
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#weighted-least-squares-wls-estimation">
   Weighted least-squares (WLS) estimation
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#using-ols-estimator-is-misleading-when-v-ne-i">
     Using OLS estimator is misleading when V
     <span class="math notranslate nohighlight">
      \(\ne\)
     </span>
     I
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#mle-under-gaussian-assumptions">
     MLE under Gaussian assumptions
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#reml">
     REML
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#robust-estimation-unstructured-covarince-matrix">
     Robust estimation (unstructured covarince matrix)
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#generalized-linear-models-glm-for-longitudinal-data">
   Generalized linear models (GLM) for longitudinal data
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#continuous-outcome">
     Continuous outcome
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#parametric-method">
       Parametric method
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#robust-method">
       Robust method
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#discrete-outcome">
     Discrete outcome
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#marginal-model-using-gee">
       Marginal model (using GEE)
      </a>
      <ul class="nav section-nav flex-column">
       <li class="toc-h5 nav-item toc-entry">
        <a class="reference internal nav-link" href="#why-gee">
         <strong>
          Why GEE
         </strong>
        </a>
       </li>
       <li class="toc-h5 nav-item toc-entry">
        <a class="reference internal nav-link" href="#details-of-gee">
         <strong>
          Details of GEE
         </strong>
        </a>
       </li>
       <li class="toc-h5 nav-item toc-entry">
        <a class="reference internal nav-link" href="#comments-on-gee">
         <strong>
          Comments on GEE
         </strong>
        </a>
       </li>
      </ul>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#appendix-limitation-of-ols-models-in-analyzing-repeated-measures-data">
   Appendix: Limitation of OLS models in analyzing repeated measures data
  </a>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Correlated/Longitudinal Data Analysis</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#cross-sectional-vs-longitudinal-data">
   Cross-sectional vs longitudinal data
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#graphic-representation-of-longitudinal-data">
   Graphic representation of longitudinal data
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#y-against-time">
     Y against Time
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#y-against-x">
     Y against X​
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#fitting-smooth-curves">
     Fitting smooth curves
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#kernel-estimation">
       Kernel estimation
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#smoothing-spline">
       Smoothing spline
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#loess">
       Loess
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#exploring-correlation-structure">
     Exploring correlation structure
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#linear-model-for-correlated-data">
   Linear model for correlated data
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#random-effect-model-conditional-model">
     Random effect model (conditional model)
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#marginal-model-population-average">
     Marginal model (population average)
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#weighted-least-squares-wls-estimation">
   Weighted least-squares (WLS) estimation
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#using-ols-estimator-is-misleading-when-v-ne-i">
     Using OLS estimator is misleading when V
     <span class="math notranslate nohighlight">
      \(\ne\)
     </span>
     I
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#mle-under-gaussian-assumptions">
     MLE under Gaussian assumptions
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#reml">
     REML
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#robust-estimation-unstructured-covarince-matrix">
     Robust estimation (unstructured covarince matrix)
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#generalized-linear-models-glm-for-longitudinal-data">
   Generalized linear models (GLM) for longitudinal data
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#continuous-outcome">
     Continuous outcome
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#parametric-method">
       Parametric method
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#robust-method">
       Robust method
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#discrete-outcome">
     Discrete outcome
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#marginal-model-using-gee">
       Marginal model (using GEE)
      </a>
      <ul class="nav section-nav flex-column">
       <li class="toc-h5 nav-item toc-entry">
        <a class="reference internal nav-link" href="#why-gee">
         <strong>
          Why GEE
         </strong>
        </a>
       </li>
       <li class="toc-h5 nav-item toc-entry">
        <a class="reference internal nav-link" href="#details-of-gee">
         <strong>
          Details of GEE
         </strong>
        </a>
       </li>
       <li class="toc-h5 nav-item toc-entry">
        <a class="reference internal nav-link" href="#comments-on-gee">
         <strong>
          Comments on GEE
         </strong>
        </a>
       </li>
      </ul>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#appendix-limitation-of-ols-models-in-analyzing-repeated-measures-data">
   Appendix: Limitation of OLS models in analyzing repeated measures data
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            
              <div>
                
  <div class="tex2jax_ignore mathjax_ignore section" id="correlated-longitudinal-data-analysis">
<h1>Correlated/Longitudinal Data Analysis<a class="headerlink" href="#correlated-longitudinal-data-analysis" title="Permalink to this headline">¶</a></h1>
<p><em>Based on course notes and blog posts<a class="footnote-reference brackets" href="#mmrm-blog" id="id1">3</a></em></p>
<div class="section" id="cross-sectional-vs-longitudinal-data">
<h2>Cross-sectional vs longitudinal data<a class="headerlink" href="#cross-sectional-vs-longitudinal-data" title="Permalink to this headline">¶</a></h2>
<ul>
<li><p><strong>Cross-sectional (CS)</strong> study can be reduced from the longitudinal study (LS) if the number of measures per subject is equal to one, ie <span class="math notranslate nohighlight">\(n_i=1\)</span>.</p>
<div class="math notranslate nohighlight">
\[
  Y_{i1}=\beta_cx_{i1}+\varepsilon_{i1}, i=1,\cdots, m
  \]</div>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\beta_c\)</span> represents the difference in average <span class="math notranslate nohighlight">\(Y\)</span> across two sub-populations which differ by one unit in <span class="math notranslate nohighlight">\(x\)</span>.</p></li>
</ul>
</li>
<li><p>With repeated measures, above model becomes LDA model:</p>
<div class="math notranslate nohighlight">
\[
  Y_{ij}=\beta_cx_{i1}+\beta_L(x_{ij}-x_{i1})+\varepsilon_{ij}, i=1,\cdots,m; j=1,\cdots,n_i
  \]</div>
<ul class="simple">
<li><p>Notice that <span class="math notranslate nohighlight">\(\beta_L\)</span> represents the expected change in <span class="math notranslate nohighlight">\(Y\)</span> over time per one unit change in <span class="math notranslate nohighlight">\(x\)</span>, w.r.t its baseline value: $<span class="math notranslate nohighlight">\((Y_{ij}-Y_{i1})=\beta_L(x_{ij}-x_{i1})+\varepsilon_{ij}-\varepsilon_{i1}\)</span>$</p></li>
<li><p>When <span class="math notranslate nohighlight">\(n=1\)</span>, above two models are identical.</p></li>
<li><p>It’s more common that <span class="math notranslate nohighlight">\(\beta_C\)</span> and <span class="math notranslate nohighlight">\(\beta_L\)</span> have the same sign. However, it may exist that they have opposite sign.</p></li>
<li><p>In CS the basis is a comparison of individuals with a particular value of <span class="math notranslate nohighlight">\(x\)</span> to others with a different value</p></li>
<li><p>In LDA each person is his/her own control. <span class="math notranslate nohighlight">\(\beta_L\)</span> is estimated by comparing a person’s response at two times assuming that <span class="math notranslate nohighlight">\(x\)</span> changes over time.</p></li>
<li><p>Estimation of <span class="math notranslate nohighlight">\(\beta_C\)</span> is confouned by unmeasured individual characteristic; while estimation of <span class="math notranslate nohighlight">\(\beta_L\)</span> is less likely to be affected by unmeasured confounding. (since, if the confounders are not time-varing, they will be cancelled out when doing model (2)-(1)).</p></li>
</ul>
</li>
</ul>
</div>
<div class="section" id="graphic-representation-of-longitudinal-data">
<h2>Graphic representation of longitudinal data<a class="headerlink" href="#graphic-representation-of-longitudinal-data" title="Permalink to this headline">¶</a></h2>
<div class="section" id="y-against-time">
<h3>Y against Time<a class="headerlink" href="#y-against-time" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>Check the time trend for every individual</p></li>
<li><p>Check the variability change over time (esp. at beginning vs end)</p></li>
</ul>
<p>Instead of using <span class="math notranslate nohighlight">\(Y\)</span>, use the standardized residuals:</p>
<div class="math notranslate nohighlight">
\[
y_{iJ}^*= \frac{y_{iJ}-\bar{y}_{\cdot J}}{s_J}
\]</div>
<div class="math notranslate nohighlight">
\[
\bar{y}_{\cdot J}=
\frac{1}{n}
\sum_{i=1}^ny_{iJ}, s_J^2=
\frac{1}{n-1}
\sum_{i=1}^n(y_{iJ}-
\bar{y}_{
\cdot J})^2
\]</div>
<ul class="simple">
<li><p><strong>Spaghetti plot</strong></p></li>
<li><p><strong>ZAP plot</strong>: using residuals</p>
<ul>
<li><p>regress <span class="math notranslate nohighlight">\(y_{ij}\)</span> on <span class="math notranslate nohighlight">\(t_{ij}\)</span> and get the residuals <span class="math notranslate nohighlight">\(r_{ij}\)</span></p></li>
<li><p>choose on dimensional summary of the residuals, for example <span class="math notranslate nohighlight">\(g_i=\text{median}(r_{i1},\cdots, r_{in_i})\)</span></p></li>
<li><p>plot <span class="math notranslate nohighlight">\(r_{ij}\)</span> vs <span class="math notranslate nohighlight">\(t_{ij}\)</span> using points (quantiles of <span class="math notranslate nohighlight">\(g_i\)</span>)</p></li>
<li><p>order units by <span class="math notranslate nohighlight">\(g_i\)</span> (min, 10th, 25th, 50th, 75th, 90th, max)</p></li>
<li><p>add lines for selected quantiles of <span class="math notranslate nohighlight">\(g_i\)</span></p></li>
</ul>
</li>
</ul>
</div>
<div class="section" id="y-against-x">
<h3>Y against X​<a class="headerlink" href="#y-against-x" title="Permalink to this headline">¶</a></h3>
<ul>
<li><p>AV plot</p></li>
<li><p>Graphic methods to separate CS information from LS information</p>
<p>The model</p>
<div class="math notranslate nohighlight">
\[
  y_{ij}=
  \beta_Cx_{i1}+
  \beta_L(x_{ij}-x_{i1})+
  \varepsilon_{ij}, i=1,
  \cdot,m; j=1,
  \cdots,n
  \]</div>
<p>suggests making two scatterplots:</p>
<p>​	i. <span class="math notranslate nohighlight">\(y_{i1}\)</span> Against <span class="math notranslate nohighlight">\(x_{i1}\)</span> for <span class="math notranslate nohighlight">\(i = 1, \cdots, m\)</span></p>
<p>​	ii. <span class="math notranslate nohighlight">\(y_{ij} - y_{i1}\)</span> against <span class="math notranslate nohighlight">\(x_{ij} - x_{i1}\)</span> for <span class="math notranslate nohighlight">\(i = 1, \cdots, m; j = 2, \cdots, n\)</span></p>
<p>From the plots, we can then ask:</p>
<p>​	i. are the differences acros subjects? (CS effect)</p>
<p>​	ii. are there changes across time within subjects? (LS effect)</p>
</li>
</ul>
</div>
<div class="section" id="fitting-smooth-curves">
<h3>Fitting smooth curves<a class="headerlink" href="#fitting-smooth-curves" title="Permalink to this headline">¶</a></h3>
<div class="math notranslate nohighlight">
\[
Y_i=
\mu(t_i)+
\varepsilon_i, i=1,
\cdots,m
\]</div>
<p>We want to estimate an unknown mean response curve <span class="math notranslate nohighlight">\(\mu(t)\)</span> in the model. Nonparametric regression models that can be used to estimate the mean response profile as a function of time.</p>
<p><em>Alawys, the smaller of the window width the less smoothness we get.</em></p>
<div class="section" id="kernel-estimation">
<h4>Kernel estimation<a class="headerlink" href="#kernel-estimation" title="Permalink to this headline">¶</a></h4>
<ul>
<li><p>selection of window centered at time <span class="math notranslate nohighlight">\(t\)</span>;</p></li>
<li><p><span class="math notranslate nohighlight">\(\hat{\mu}(t)\)</span> is the average of <span class="math notranslate nohighlight">\(Y\)</span> of all points that are visible in that window</p></li>
<li><p>slide a window from the extreme left to extreme right, calculating <span class="math notranslate nohighlight">\(\hat{
\mu}(t_i)\)</span> for each</p></li>
<li><p>a “better” method is to use a weight function that changes smoothly with time and gives weights to the observations closer to <span class="math notranslate nohighlight">\(t\)</span>. E.g. Gaussian kernel <span class="math notranslate nohighlight">\(K(t_i)=\exp(-0.5t_i^2)\)</span> (i.e. <span class="math notranslate nohighlight">\(N(0,1))\)</span></p></li>
<li><p>at window with <span class="math notranslate nohighlight">\(t=t_1\)</span>,</p>
<div class="math notranslate nohighlight">
\[
  \hat{
  \mu}(t_1)=
  \sum_{i=1}^m
  \omega(t_1,t_i,h)y_i/
  \sum_{i=1}^m
  \omega(t_1,t_i,h)
  \]</div>
<p>Where <span class="math notranslate nohighlight">\(h\)</span> controls the smoothness.</p>
</li>
</ul>
</div>
<div class="section" id="smoothing-spline">
<h4>Smoothing spline<a class="headerlink" href="#smoothing-spline" title="Permalink to this headline">¶</a></h4>
<ul>
<li><p>Smoothing spline (cubic): the function <span class="math notranslate nohighlight">\(s(t)\)</span> that minimizes the criterion</p>
<div class="math notranslate nohighlight">
\[
  J(
  \lambda)=
  \sum_{i=1}^m
  \{y_i-s(t_i)
  \}^2+
  \lambda
  \int s''(t)^2dt
  \]</div>
</li>
<li><p><span class="math notranslate nohighlight">\(s(t)\)</span> Satisfies the criterion if and only if it is a piecewise cubic polynomial</p></li>
<li><p><span class="math notranslate nohighlight">\(\lambda\)</span> Smaller <span class="math notranslate nohighlight">\(\Rightarrow\)</span> curve less smooth</p></li>
<li><p><span class="math notranslate nohighlight">\(\int s''(t)^2dt\)</span>: roughness penalty</p></li>
</ul>
</div>
<div class="section" id="loess">
<h4>Loess<a class="headerlink" href="#loess" title="Permalink to this headline">¶</a></h4>
<ol class="simple">
<li><p>Center a window at time <span class="math notranslate nohighlight">\(t_i\)</span></p></li>
<li><p>fit weighted least squares</p></li>
<li><p>Calculate the residuals</p></li>
<li><p>Down weight the outliers and repeat 1, 2, 3 many times</p></li>
<li><p>the result is a fitted line that is insensitive to the observations with outlying <span class="math notranslate nohighlight">\(Y\)</span> values</p></li>
</ol>
</div>
</div>
<div class="section" id="exploring-correlation-structure">
<h3>Exploring correlation structure<a class="headerlink" href="#exploring-correlation-structure" title="Permalink to this headline">¶</a></h3>
<ul>
<li><p>Let <span class="math notranslate nohighlight">\(y_{ij}=\beta_0+x_{ij}\beta+\varepsilon_{ij}\)</span>, we should be clear that</p>
<div class="math notranslate nohighlight">
\[
  cor(y_{ij},y_{ik})
  \ne cor(
  \varepsilon_{ij},
  \varepsilon_{ik})=cor(y_{ij},y_{ik}|x_{ij},x_{ik})
  \]</div>
<p>similarly, <span class="math notranslate nohighlight">\(var(y) \ne var(\varepsilon)\)</span>.</p>
</li>
<li><p>We explore the correlation structure based on the residuals of the model. And it is used for <strong>equally spaced</strong> data, not for irregular data.</p></li>
<li><p><strong>Weakly stationary</strong>: if residuals have constant mean and variance and if <span class="math notranslate nohighlight">\(corr(y_{ij}, y_{ik})\)</span> depends only on <span class="math notranslate nohighlight">\(|t_{ij}- t_{ik}|\)</span>, then the process <span class="math notranslate nohighlight">\(Y_{ij}\)</span> is said to be weakly stationary.</p></li>
<li><p><strong>Autocorrelation function (ACF)</strong></p>
<div class="math notranslate nohighlight">
\[
  \rho(u)=corr(Y_{ij},Y_{ij-u})
  \]</div>
<p>for all <span class="math notranslate nohighlight">\(i\)</span>, which is pooling observation pairs along the diagonals of the scatter plot matrix.</p>
<div class="math notranslate nohighlight">
\[
  se(
  \rho(u))
  \approx 1/
  \sqrt{N}
  \]</div>
<p>Where <span class="math notranslate nohighlight">\(N\)</span> is the number of independent pairs in the calculation.</p>
</li>
<li><p>ACF is most effective for studying equally spaced data that are roughly</p>
<p>stationary.</p>
</li>
<li><p>For irreguarly-sapced data, we can use <strong>Variogram</strong>:</p>
<div class="math notranslate nohighlight">
\[
  \gamma(u)=
  \frac{1}{2}E
  \left[
  \{Y(t)-Y(t-u)
  \}^2
  \right], u
  \ge 0
  \]</div>
</li>
<li><p>If <span class="math notranslate nohighlight">\(Y(t)\)</span> is <em>stationary</em>, the Variogram is directly related to the ACF <span class="math notranslate nohighlight">\(\rho(u)\)</span> by</p>
<div class="math notranslate nohighlight">
\[
  \gamma(u)=
  \sigma^2
  \{1-
  \rho(u)
  \}
  \]</div>
<p>Where <span class="math notranslate nohighlight">\(\sigma^2\)</span> is the variance of <span class="math notranslate nohighlight">\(Y\)</span>:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
  \begin{align*}
  E(X-Y)^2 &amp;= [E(X-Y)]^2+Var(X-Y)\\
  &amp;= 0+Var(X)+Var(Y)-2Cov(X,Y)\\
  &amp;= 2\sigma^2-2\rho\sigma^2\\
  &amp;= \sigma^2(1-\rho)
  \end{align*}
  \end{split}\]</div>
</li>
<li><p>Calculating <span class="math notranslate nohighlight">\(\gamma(u)\)</span>, the Vriagram:</p>
<ul>
<li><p>Starging with the residulas <span class="math notranslate nohighlight">\(r_{ij}\)</span> and the time <span class="math notranslate nohighlight">\(t_{ij}\)</span>, compute all possible</p>
<div class="math notranslate nohighlight">
\[
    v_{ijk}=
    \frac{1}{2}(r_{ij}-r_{ik})^2
    \]</div>
<p>and</p>
<div class="math notranslate nohighlight">
\[
    u_{ijk}=t_{ij}-t_{ik}
    \text{ for } j&lt;k
    \]</div>
</li>
<li><p>Smooth <span class="math notranslate nohighlight">\(v_{ijk}\)</span> against <span class="math notranslate nohighlight">\(u_{ijk}\)</span> (using lowess)</p></li>
<li><p>Estimate the total variance as</p>
<div class="math notranslate nohighlight">
\[
    \hat{
    \sigma}^2=
    \frac{1}{N-1}
    \sum_{ij}(r_{ij}-
    \bar{r})^2
    \]</div>
</li>
<li><p>If the time <span class="math notranslate nohighlight">\(t_{ij}\)</span> are not total irregular, i.e. there will be more than one observations at each vlaue of <span class="math notranslate nohighlight">\(u\)</span>. Then let</p>
<div class="math notranslate nohighlight">
\[
    \hat{
    \gamma}(u)=
    \frac{
    \sum_{i=1}^{n_i}v_{ijk}}{n_i}
    \]</div>
</li>
</ul>
</li>
</ul>
</div>
</div>
<div class="section" id="linear-model-for-correlated-data">
<h2>Linear model for correlated data<a class="headerlink" href="#linear-model-for-correlated-data" title="Permalink to this headline">¶</a></h2>
<ul>
<li><p>To develop a general linear model framework for longitudinal data, in which</p>
<p>the inference we make about the parameters of interest (<span class="math notranslate nohighlight">\(\beta\)</span>) <em>recoginze the likely correlation structure of the data</em>. There are two ways to archieve this:</p>
<ol class="simple">
<li><p>To build explicit parametric models of the covariance struture (e.g. CS/exchangable, AR(1), etc.) -&gt; MMRM</p></li>
<li><p>To use methods of inference which are robust to misspecification of the covariance structure<a class="footnote-reference brackets" href="#id4" id="id2">1</a><a class="footnote-reference brackets" href="#id5" id="id3">2</a></p></li>
</ol>
</li>
</ul>
<div class="section" id="random-effect-model-conditional-model">
<h3>Random effect model (conditional model)<a class="headerlink" href="#random-effect-model-conditional-model" title="Permalink to this headline">¶</a></h3>
<div class="math notranslate nohighlight">
\[
Y_{ij} = U_i + \beta_0 + \beta_1t_j + \epsilon_{ij}
\]</div>
<p>Where</p>
<div class="math notranslate nohighlight">
\[
U_i \sim N(0, v^2), \text{variantion between units/clusters}
\]</div>
<div class="math notranslate nohighlight">
\[
\epsilon_{ij} \sim N(0, \tau^2), \text{variantion within units }
\]</div>
<p>​	<span class="math notranslate nohighlight">\(\rho = \frac{v^2}{v^2 + \tau^2}\)</span>, proportion of total variance due to between-unit variation</p>
<ul>
<li><p><span class="math notranslate nohighlight">\(var(y_{ij}|U_i) = \tau^2, cov(y_{ij}, y_{ij'}|U_i)=0\)</span></p></li>
<li><p>Example: random effect (repeated measures) ANOVA:</p>
<ul>
<li><p>we can treat the group (condition) variable as the orignial “time” variable, i.e. the repeated meaures are observed on different conditions (which cause the groups effect that we are interested in).</p>
<div class="math notranslate nohighlight">
\[
    y_{ij} = \mu_j + U_i + \epsilon_{ij}
    \]</div>
<p>where</p>
<div class="math notranslate nohighlight">
\[
    \mu_j, j=1, \cdots, n \text{ is the group effects}
    \]</div>
<div class="math notranslate nohighlight">
\[
    U_i \sim N(0, v^2) \text{ is the between subjects random effect}
    \]</div>
<div class="math notranslate nohighlight">
\[
    \epsilon_{ij} \sim N(0, \tau^2) \text{ is the random error}
    \]</div>
</li>
<li><p>Total sum of squares = between group sum of squares + within group sum of squares</p></li>
</ul>
<div class="math notranslate nohighlight">
\[\begin{split}
    \begin{equation}
      Cov(y_{ij}, y_{i'j'}) =
        \begin{cases}
          var(y_{ij}) &amp; \text{if $i=i'$, $j=j'$}\\
          cov(y_{ij}, y_{ij'}) &amp; \text{if $i=i, j\ne j'$}\\
          0 &amp; \text{if $i\ne i, j\ne j'$}
        \end{cases}       
    \end{equation}
    \end{split}\]</div>
<div class="math notranslate nohighlight">
\[
    corr(y_{ij}, y_{ij'}) = \frac{cov(y_{ij}, y_{ij'})}{\sqrt{var(y_{ij})\cdot var(y{ij'})}} = \frac{v^2}{\tau^2+v^2} = \rho \text{ (within cluster/subject correlation)}
    \]</div>
</li>
<li><p><strong>Heteogeneity</strong>: variation between groups implies (relative) similarity/correlation within groups. If <span class="math notranslate nohighlight">\(v^2 &gt;&gt; \tau^2 \Rightarrow \rho \rightarrow 1 \Rightarrow\)</span> significant difference between groups.</p></li>
</ul>
</div>
<div class="section" id="marginal-model-population-average">
<h3>Marginal model (population average)<a class="headerlink" href="#marginal-model-population-average" title="Permalink to this headline">¶</a></h3>
<ol>
<li><p>With <strong>exchangable (or CS)</strong> variance-covariance structure (balanced data)</p>
<div class="math notranslate nohighlight">
\[\begin{split}
   Y_{ij} = \beta_0+\beta_1t_j+\epsilon_{ij}, i=1, \cdots, m; j=1, \cdots, n\\
   Cov(Y_i) = \sigma^2V_0\\
   \end{split}\]</div>
<p>where</p>
<div class="math notranslate nohighlight">
\[\begin{split}
   V_0 = \rho J+(1-\rho)I\\
   \rho=corr(y_{ij}, y_{ij'}), \text{ for $j \ne j'$}
   \end{split}\]</div>
<ul class="simple">
<li><p><strong>Marginal model with CS variance structure is equivalent with random effect (intercept) model</strong>: the same <span class="math notranslate nohighlight">\(E(Y_i)\)</span> and <span class="math notranslate nohighlight">\(Cov(Y_i)\)</span> structures, thus wil return the same estimate of the parameters.</p></li>
</ul>
</li>
<li><p><strong>Exponential correlation/autoregressive</strong> model</p>
<ul>
<li><p>Correlation b/t a pair of measurements of the same subject decays towards 0 as the time separation b/t the measurement increases, i.e.</p>
<ul>
<li><p>For unequally-spaced data</p>
<div class="math notranslate nohighlight">
\[
       cov(y_{ij}, y_{ik}) = (V_0)_{ij} = v_ij = \sigma^2e^{-\phi|t_j-t_k|}
       \]</div>
</li>
<li><p>For equally-spaced data</p>
<div class="math notranslate nohighlight">
\[
       t_{j-1}-t_j = d
       \]</div>
<p>For all <span class="math notranslate nohighlight">\(j\)</span>, then <span class="math notranslate nohighlight">\(v_{jk}=\sigma^2\rho\)</span>, where <span class="math notranslate nohighlight">\(\rho=\exp(-\phi d)\)</span> is the correlation b/t successive observations on the same subject.</p>
</li>
</ul>
</li>
<li><p>In marginal model, we model the mean and the covariance strucutre separately:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
     E(Y_i) = \mu = X_i\beta\\
     Cov(Y_i) = CS/AR(1)/...
     \end{split}\]</div>
</li>
<li><p>Three basic elements of correlation structures:</p>
<ul class="simple">
<li><p>Random effects</p></li>
<li><p>Autocorrelation or serial dependence</p></li>
<li><p>Noise, measurements error</p></li>
</ul>
</li>
<li><p>Modelling the correlation in longitudinal data is important to be able to obtain correct inference on <span class="math notranslate nohighlight">\(\beta\)</span>s. Incorporating correlation into estimation of regression models is achieved via <strong>weighted least squares</strong>.</p></li>
</ul>
</li>
</ol>
</div>
</div>
<div class="section" id="weighted-least-squares-wls-estimation">
<h2>Weighted least-squares (WLS) estimation<a class="headerlink" href="#weighted-least-squares-wls-estimation" title="Permalink to this headline">¶</a></h2>
<p><em>All following etimators are weighted LS etimators, the difference is in the choince of the weight and its impact on the variance (thus the interval) estimation of beta.</em></p>
<ul class="simple">
<li><p>(no distribution assumption on <span class="math notranslate nohighlight">\(y\)</span>) The <strong>weighted least-squares</strong> estimator of <span class="math notranslate nohighlight">\(\beta\)</span>, using a symmetric <em>weight matrix</em>, <span class="math notranslate nohighlight">\(W\)</span>, is the value <span class="math notranslate nohighlight">\(\hat{\beta}_W\)</span>, which minimize the quadratic form</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
(y-X\beta)'W(y-X\beta)'
\]</div>
<ul>
<li><p>Standard matrix manipulations give the explicit result</p>
<div class="math notranslate nohighlight">
\[
  \hat{\beta}_W = (X'WX)^{-1}X'Wy
  \]</div>
<ul class="simple">
<li><p>It’s an unbiased estimator of <span class="math notranslate nohighlight">\(\beta\)</span>, whatever the choice of <span class="math notranslate nohighlight">\(W\)</span>.</p></li>
<li><p><span class="math notranslate nohighlight">\(\text{Var}(\hat{\beta}_W) = \sigma^2\{(X'WX)^{-1}X'W\}V\{WX(X'WX)^{-1}\}\)</span></p></li>
<li><p>When <span class="math notranslate nohighlight">\(W = I\)</span>, it reduces to the OLS estimator <span class="math notranslate nohighlight">\(\hat{\beta}_I = (X'X)^{-1}X'y\)</span>, with <span class="math notranslate nohighlight">\(\text{Var}(\hat{\beta}_I) = \sigma^2(X'X)^{-1}X'VX(X'X)^{-1}\)</span></p></li>
<li><p>When <span class="math notranslate nohighlight">\(W = V^{-1}\)</span>, the estimator becomes the MLE (<strong>under the assumption of normal distribution</strong>): <span class="math notranslate nohighlight">\(\hat{\beta} = (X'V^{-1}X)^{-1}X'V^{-1}y\)</span> with <span class="math notranslate nohighlight">\(\text{Var}(\hat{\beta}) = \sigma^2(X'V^{-1}X)^{-1}\)</span></p></li>
</ul>
</li>
<li><p>According to the <a class="reference external" href="https://en.wikipedia.org/wiki/Gauss%E2%80%93Markov_theorem">Gauss-Markov theorem</a>, the MLE is the most efficient linear estimator for <span class="math notranslate nohighlight">\(\beta\)</span>. However, to identify this optimal weighting matrix we need to know the complete correlation structure of the data - we don’t need to know <span class="math notranslate nohighlight">\(\sigma^2\)</span>, because <span class="math notranslate nohighlight">\(\hat{\beta}_W\)</span> is unchanged by proportional changes in all the elements of <span class="math notranslate nohighlight">\(W\)</span>.</p></li>
<li><p>Also, because the correlation structure may be difficult to identify in practice, it is of interest to ask how much loss of efficiency might result from using a different <span class="math notranslate nohighlight">\(W\)</span></p></li>
<li><p>When we know the correlation structure is CS (uniform/exchangable), the OLS is fully efficient as the WLS estimator; an intuitive explanation is that with a common correlation b/t any two equally spaced measurements on the same unit, there is no reason to weight measurements differently.</p></li>
</ul>
<div class="section" id="using-ols-estimator-is-misleading-when-v-ne-i">
<h3>Using OLS estimator is misleading when V <span class="math notranslate nohighlight">\(\ne\)</span> I<a class="headerlink" href="#using-ols-estimator-is-misleading-when-v-ne-i" title="Permalink to this headline">¶</a></h3>
<ul>
<li><p>In many circumstances where there is balanced design, the OLS estimator, <span class="math notranslate nohighlight">\(\tilde{\beta}\)</span>, is perfectly satisfactory for point estimation. But this is not always the case. (Example in book page 63)</p></li>
<li><p>Even when OLS is reasonably efficient, it is clear from the form of its variance</p>
<div class="math notranslate nohighlight">
\[
  \text{Var}(\tilde{\beta}) =\sigma^2(X'X)^{-1}X'VX(X'X)^{-1}
  \]</div>
<p>That interval estimation for <span class="math notranslate nohighlight">\(\beta\)</span> still requires information about <span class="math notranslate nohighlight">\(\sigma^2 V\)</span>, the variance matrix of the data. In particular, the usual formula for the variance of the least-squares estimator,</p>
<div class="math notranslate nohighlight">
\[
  \text{Var}(\tilde{\beta}) = \sigma^2(X'X)^{-1}
  \]</div>
<p>Assumes that <span class="math notranslate nohighlight">\(V = I\)</span>, the identify matrix, and can be seriously misleading when it is not so.</p>
</li>
<li><p>A naive use of OLS would be to ignore the correlation structure in the data and to base interval estimation for <span class="math notranslate nohighlight">\(\beta\)</span> on the variance above with <span class="math notranslate nohighlight">\(\sigma^2\)</span> being replaced with its usual estimator, the residual mean square</p>
<div class="math notranslate nohighlight">
\[
  \tilde{\sigma}^2 = (nm - p)^{-1}(y-X\tilde{\beta})'(y-X\tilde{\beta})
  \]</div>
<p>There are two sources of error in this native approach when <span class="math notranslate nohighlight">\(V \ne I\)</span>:</p>
<ol class="simple">
<li><p><span class="math notranslate nohighlight">\(\text{Var}(\tilde{\beta})\)</span> is wrong</p></li>
<li><p><span class="math notranslate nohighlight">\(\tilde{\sigma}^2\)</span> is no longer an unbiased estimator of <span class="math notranslate nohighlight">\(\sigma^2\)</span></p></li>
</ol>
</li>
</ul>
</div>
<div class="section" id="mle-under-gaussian-assumptions">
<h3>MLE under Gaussian assumptions<a class="headerlink" href="#mle-under-gaussian-assumptions" title="Permalink to this headline">¶</a></h3>
<ul>
<li><p>Simultaneous estimtation of the parameter of interest <span class="math notranslate nohighlight">\(\beta\)</span> and of covariance parameters <span class="math notranslate nohighlight">\(\sigma^2\)</span> and <span class="math notranslate nohighlight">\(V_0\)</span> using the likelihood function (<em>profile likelihood</em> method)</p></li>
<li><p>The log-likelihood function for observed data <span class="math notranslate nohighlight">\(y\)</span> is</p>
<div class="math notranslate nohighlight">
\[
  L(\beta, \sigma^2, V_0) = -0.5\{nm\log(\sigma^2) + m\log(|V_0|) + \sigma^{-2}(y-X\beta)'V_0^{-1}(y-X\beta)\}
  \]</div>
<ol>
<li><p>By fixing <span class="math notranslate nohighlight">\(V_0\)</span> and <span class="math notranslate nohighlight">\(\sigma^2\)</span> first, we calculate</p>
<div class="math notranslate nohighlight">
\[
     \hat{\beta}(V) = (X'V^{-1}X)^{-1}X'V^{-1}y
     \]</div>
</li>
<li><p>Maximize <span class="math notranslate nohighlight">\(L(\hat{\beta(V), \sigma^2, V_0})\)</span> w.r.t. <span class="math notranslate nohighlight">\(\sigma^2\)</span> and get</p>
<div class="math notranslate nohighlight">
\[
     \hat{\sigma}^2(V_0) = RSS(V_0)/nm
     \]</div>
<p>where <span class="math notranslate nohighlight">\(RSS(V_0) = (y - X\hat{\beta}(V_0))'V^{-1}(y - X\hat{\beta}(V_0))\)</span></p>
</li>
<li><p>Then maximize the updated likelihood w.r.t. <span class="math notranslate nohighlight">\(V_0\)</span> and get <span class="math notranslate nohighlight">\(\hat{V}_0\)</span></p></li>
</ol>
</li>
<li><p>By using the profile likelihood method, we gain computational advantage (since we reduce the number of parameters to be maximized in one iteration)  since there are closed forms for the MLEs.</p></li>
</ul>
</div>
<div class="section" id="reml">
<h3>REML<a class="headerlink" href="#reml" title="Permalink to this headline">¶</a></h3>
<ul>
<li><p>To improve the estimation of the <span class="math notranslate nohighlight">\(\sigma^2\)</span> from MLE, which is biased, to get an unbiased estimator based on the linearly transformed set of data <span class="math notranslate nohighlight">\(\bf{Y}^* = \bf{AY}\)</span> such that the distribution of <span class="math notranslate nohighlight">\(\bf{Y}^*\)</span> doesn’t depend on <span class="math notranslate nohighlight">\(\beta\)</span></p></li>
<li><p>We call the likelihood for the transformed data <span class="math notranslate nohighlight">\(\bf{Y}^*\)</span> marginal likelihood for <span class="math notranslate nohighlight">\(\sigma^2\)</span> and <span class="math notranslate nohighlight">\(V_0\)</span> since it doesn’t contain <span class="math notranslate nohighlight">\(\beta\)</span> parameters</p></li>
<li><p>We choose the transforming matrix <span class="math notranslate nohighlight">\(\bf{A}\)</span> as</p>
<div class="math notranslate nohighlight">
\[
  \bf{A = I - X(X'X)^{-1}X'}
  \]</div>
<p>However, this matrix is singular. To obtain a non-singular distribution, we can use only <span class="math notranslate nohighlight">\(N-p\)</span> rows of the <span class="math notranslate nohighlight">\(\bf{A}\)</span> matrix. Actually, the estimators for <span class="math notranslate nohighlight">\(\sigma^2\)</span> and <span class="math notranslate nohighlight">\(V\)</span> do not depend on which rows we use, nor on the particular choice of <span class="math notranslate nohighlight">\(\bf{A}\)</span>: any full-rank matrix with the property that <span class="math notranslate nohighlight">\(E(\bf{Y}^*) = 0\)</span> for all <span class="math notranslate nohighlight">\(\beta\)</span> will give the same answer.</p>
</li>
</ul>
</div>
<div class="section" id="robust-estimation-unstructured-covarince-matrix">
<h3>Robust estimation (unstructured covarince matrix)<a class="headerlink" href="#robust-estimation-unstructured-covarince-matrix" title="Permalink to this headline">¶</a></h3>
<ul>
<li><p>Not willing to specify a parameteric model for the covariance structure <span class="math notranslate nohighlight">\(V\)</span> for <span class="math notranslate nohighlight">\(\bf{Y}\)</span>, a “robust” estimation of <span class="math notranslate nohighlight">\(\beta\)</span> resembles the form of a WLS estimator by using the <strong>working covariance matrix</strong> (weight) <span class="math notranslate nohighlight">\(W\)</span>:</p>
<div class="math notranslate nohighlight">
\[
  \tilde{\beta}_W = (X'WX)^{-1}X'Wy
  \]</div>
<p>and the variance of <span class="math notranslate nohighlight">\(\tilde{\beta}_W\)</span> takes a sandwich form:</p>
<div class="math notranslate nohighlight">
\[
  \hat{R}_W = \{(X'WX)^{-1}X'W\}\hat{V}\{(X'WX)^{-1}X'W\}
  \]</div>
<p>where <span class="math notranslate nohighlight">\(\hat{V}\)</span> is a consistent estimate for <span class="math notranslate nohighlight">\(V\)</span> whatever the true covariance structure is.</p>
</li>
<li><p>Robust estimation of <span class="math notranslate nohighlight">\(V\)</span></p>
<ul>
<li><p>Data: <span class="math notranslate nohighlight">\(\{y_{hij}\}, h = 1, \cdots, g; i = 1, \cdots, m_h; j = 1, \cdots, n\)</span>, where <span class="math notranslate nohighlight">\(h\)</span> = treatment, <span class="math notranslate nohighlight">\(i=\)</span> subject, and <span class="math notranslate nohighlight">\(j=\)</span> time point.</p></li>
<li><p>Let <span class="math notranslate nohighlight">\(E(Y_{hij}) = \mu_{hj}, h = 1, \cdots, g; j = 1, \cdots, n.\)</span> A <em>saturated model</em> for the covariance matrix assumes</p>
<div class="math notranslate nohighlight">
\[
    \text{Var}(Y) = V,
    \]</div>
<p>With non-zero diagnola blocks equal to <span class="math notranslate nohighlight">\(V_0\)</span>, a positive definite but otherwise arbitrary <span class="math notranslate nohighlight">\(n \times n\)</span> matrix.</p>
</li>
<li><p>The REML estimator for <span class="math notranslate nohighlight">\(V_0\)</span> is:</p>
<div class="math notranslate nohighlight">
\[
    \hat{V}_0 = (\sum_{h=1}^g m_h - g)^{-1}\times\sum_{h=1}^g\sum_{i=1}^{m_h}(y_{hi}-\hat{{\bf\mu}}_h)(y_{hi}- \hat{{\bf\mu}}_{h})'
    \]</div>
<p>where</p>
<div class="math notranslate nohighlight">
\[\begin{split}
    {\bf y}_{hi} = (y_{hi1}, \cdots, y_{hin})'\\
    {\bf\mu}_h = (\mu_{h1}, \cdots, \mu_{hn})'\\
    \hat{\mu}_{hj} = \frac{1}{m_h}\sum_{i=1}^{m_h}y_{hij}, j = 1, \cdots, n
    \end{split}\]</div>
</li>
</ul>
</li>
<li><p>The MLE of <span class="math notranslate nohighlight">\(V\)</span>: when the saturated model strategy is not feasible, typically when data are from observational studies with continuous covariates, we can estimate <span class="math notranslate nohighlight">\(V\)</span> by maximizaing the likelihood - however this approach depends on how <span class="math notranslate nohighlight">\(V\)</span> is.</p></li>
<li><p>For <strong>unlalanced data</strong>, <span class="math notranslate nohighlight">\(V\)</span> is still block diagonal, but the <span class="math notranslate nohighlight">\(V_{0i}\)</span> will have different sizes. We can estimate <span class="math notranslate nohighlight">\(V_{0i}\)</span> as</p>
<div class="math notranslate nohighlight">
\[
  \hat{V}_{0i} = ({\bf y}_i - \hat{\bf \mu}_i)({\bf y}_i - \hat{\bf \mu}_i)',
  \]</div>
<p>Where <span class="math notranslate nohighlight">\(\hat{\bf \mu}_i\)</span> is the OLS estimate of <span class="math notranslate nohighlight">\({\bf \mu}_i\)</span> from the <em>most complicated model</em> we are prepared to entertain for the mean response.</p>
</li>
<li><p>The steps can be summarized as follows</p>
<ol>
<li><p>Specify saturated model for the mean</p>
<div class="math notranslate nohighlight">
\[
     E(Y_{hij}) = \mu_{hij}
     \]</div>
</li>
<li><p>Estimate <span class="math notranslate nohighlight">\(\mu_{hj}\)</span> by OLS and get <span class="math notranslate nohighlight">\(\hat{\mu}_{hj}\)</span></p></li>
<li><p>REML estimate of <span class="math notranslate nohighlight">\(\hat{V}_0\)</span></p></li>
<li><p>By using <span class="math notranslate nohighlight">\(\hat{V}_0\)</span>, we get robust s.e. estimate for <span class="math notranslate nohighlight">\(\beta\)</span></p></li>
</ol>
</li>
<li><p>Robust estimation v.s. parametric approach</p>
<ul>
<li><p>The crucial difference b/t these two methods is that, with robust estimation, a poor choice of <span class="math notranslate nohighlight">\(W\)</span> will affect only the efficiency of the inference for <span class="math notranslate nohighlight">\(\beta\)</span>, not the validity.</p></li>
<li><p>CI and hypothesis tests are derived from</p>
<div class="math notranslate nohighlight">
\[
    \tilde{\beta}_W \sim MVN(\beta, \hat{R}_W)
    \]</div>
<p>which will be asymptotically correct whatever. the true form of <span class="math notranslate nohighlight">\(V\)</span>.</p>
</li>
<li><p>We can get consistent estimate of <span class="math notranslate nohighlight">\(V\)</span> by REML under a saturated model.</p></li>
</ul>
</li>
<li><p>Comparison</p>
<ul class="simple">
<li><p>Efficiency: optimal weighted least-squares estimate uses a weight matrix whose inverse is proportional to the true covariance matrix so it would seem reasonable to use the data to estimate this optimal weight matrix.</p></li>
<li><p>The robust estimation also requires to estimate the V matrix using the data, however it always involves more parameters (total <span class="math notranslate nohighlight">\(n(n + 1)/2\)</span> in unstructured) than the covariance matrix under parametric assumption.</p></li>
<li><p>So the robust approach is usually satisfactory when the data consist of short, complete sequence of measurements observed at a common set of times on many experimental units, and care is taken in the choice of the working correlation matrix. In other circumstance, it is worth considering a parametric modeling approach.</p></li>
</ul>
</li>
</ul>
</div>
</div>
<div class="section" id="generalized-linear-models-glm-for-longitudinal-data">
<h2>Generalized linear models (GLM) for longitudinal data<a class="headerlink" href="#generalized-linear-models-glm-for-longitudinal-data" title="Permalink to this headline">¶</a></h2>
<div class="mermaid">
            graph TD

a[GLM for longitudinal data] --&gt; b[Continuous outcome: identity link]
a --&gt; c[Discrete outcome: logit/log link]
b --&gt; d[&quot;Is var(Yi) known?&quot;]
d -- Yes --&gt; e[WLS]
d -- No --&gt; f[&quot;model var(Yi) in addition to E(Yi|Xi)?&quot;]
f -- Yes --&gt; g[marginal model]
g --&gt; g1[MLE]
g --&gt; g2[RMLE]
f -- No --&gt; h[Robust estimation]
c --&gt; i[Marginal mdoel]
c --&gt; j[Trasitional model]
c --&gt; k[random effect model]
i --&gt; i1[GEE: quasi-likelihood]
j --&gt; l[Likelihood based]
k --&gt; l
b --&gt; i1
        </div><ul class="simple">
<li><p>G(eneralized) is used for non-normal outcoes</p></li>
<li><p>GEE is used for correlated data, and for both continuous and discrete outcomes; when used in continuous outcome, it is equivalent to LMM (linear mixed model)</p></li>
<li><p>GEE and GLMM (generalized linear mixed model) are not equivalent as <span class="math notranslate nohighlight">\(E(g(x))\ne g(E(x))\)</span>, where <span class="math notranslate nohighlight">\(g(\cdot)\)</span> is a non-linear function (or transformation).</p></li>
</ul>
<div class="section" id="continuous-outcome">
<h3>Continuous outcome<a class="headerlink" href="#continuous-outcome" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>When we don’t know the true variance-covariance structure of <span class="math notranslate nohighlight">\(\bf{Y}_i\)</span>, we mainly have to options: impose paramatric assumption of the covariance structure or leave it unspecied (robust method).</p></li>
<li><p>Essentially, the estimate of <span class="math notranslate nohighlight">\(\beta\)</span> has the form of weighted least squares no matter which method we use, and it’s valid. The dierence lies on <span class="math notranslate nohighlight">\(\text{var}(\beta)\)</span>, depending on the different weights that are assumed.</p></li>
</ul>
<div class="section" id="parametric-method">
<h4>Parametric method<a class="headerlink" href="#parametric-method" title="Permalink to this headline">¶</a></h4>
<ul>
<li><p>Parametric model on <span class="math notranslate nohighlight">\(\text{var}(Y_i)\)</span>. The model is then fully specied: first two moments and distribution, then we can use ML or REML method to find the MLE of the parameters and make inference on them.</p></li>
<li><p>The advantage on of REML over ML is that, the ML estimates of the variance components, <span class="math notranslate nohighlight">\(\sigma^2\)</span> the diagnoal part, is biased. Using REML can avoid this and get unbiased estimates.</p></li>
<li><p>The MLE of <span class="math notranslate nohighlight">\(\sigma^2\)</span>, <span class="math notranslate nohighlight">\(\hat{\sigma}^2 = RSS/(nm)\)</span>, where <span class="math notranslate nohighlight">\(RSS\)</span> is the residual sum of squares and <span class="math notranslate nohighlight">\(nm\)</span> is the number of observations in total. While the RMLE of <span class="math notranslate nohighlight">\(\sigma^2\)</span> is <span class="math notranslate nohighlight">\(\tilde{\sigma}^2 = RSS/(nm-p)\)</span>, where <span class="math notranslate nohighlight">\(p\)</span> is the number of elements in <span class="math notranslate nohighlight">\(\beta\)</span>.</p></li>
<li><p>For <span class="math notranslate nohighlight">\({\bf Y} \sim MVN(X\beta, \sigma^2V)\)</span>, the MLEs are found by using profile likelihood technique:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
  \hat{V}_0 = \arg\max L_r(V_0)\\
  \hat{\beta} = \hat{\beta}(\hat{V}_0)\\
  \hat{\sigma}^2 = \hat{\sigma}^2(\hat{V}_0)
  \end{split}\]</div>
</li>
<li><p>Note that <span class="math notranslate nohighlight">\(V_0\)</span> has effect on <span class="math notranslate nohighlight">\(\hat{\beta}\)</span> for its variance but not expectation.</p></li>
</ul>
</div>
<div class="section" id="robust-method">
<h4>Robust method<a class="headerlink" href="#robust-method" title="Permalink to this headline">¶</a></h4>
<ul>
<li><p>Without assuming the parametric form of <span class="math notranslate nohighlight">\(\text{var}({\bf Y}_i)\)</span>, we may select a “working” covariance matrix as the weight, say <span class="math notranslate nohighlight">\(W\)</span>. Then the robust estimate of <span class="math notranslate nohighlight">\(\beta\)</span> is given by</p>
<div class="math notranslate nohighlight">
\[
  \tilde{\beta}_W = (X'WX)^{-1}X'Wy
  \]</div>
<p>With variance</p>
<div class="math notranslate nohighlight">
\[
  \hat{R}_W = \{(X'WX)^{-1}X'W\}\hat{V}\{(X'WX)^{-1}X'W\}
  \]</div>
<p>Where <span class="math notranslate nohighlight">\(\hat{V}\)</span> is a consistent estimate of <span class="math notranslate nohighlight">\(V\)</span> whatever the true covariance structure is.</p>
</li>
</ul>
</div>
</div>
<div class="section" id="discrete-outcome">
<h3>Discrete outcome<a class="headerlink" href="#discrete-outcome" title="Permalink to this headline">¶</a></h3>
<div class="section" id="marginal-model-using-gee">
<h4>Marginal model (using GEE)<a class="headerlink" href="#marginal-model-using-gee" title="Permalink to this headline">¶</a></h4>
<div class="section" id="why-gee">
<h5><strong>Why GEE</strong><a class="headerlink" href="#why-gee" title="Permalink to this headline">¶</a></h5>
<ul class="simple">
<li><p>We can not easily generalize the rules used in continuous type outcome to discrete outcome, since there is no ready to use multivariate version of discrete distributions corresponding to the univariate ones (binomial/Poisson)</p></li>
<li><p><strong>Simplicity</strong>: formulating quasi-score equation only needs to specify the first two moments of the outcomes; the variance is always a function of the mean of the outcome</p></li>
<li><p><strong>Consistency</strong>: despite the miss specification fo the covariance structure, the estimate of the regression coefficient is still valid. The specification of variance only affect the efficiency of the estimated coefficient, if the variance structure is correctly specified, the estimate is MLE and most efficient.</p></li>
</ul>
</div>
<div class="section" id="details-of-gee">
<h5><strong>Details of GEE</strong><a class="headerlink" href="#details-of-gee" title="Permalink to this headline">¶</a></h5>
<ul>
<li><p>GEE function:</p>
<div class="math notranslate nohighlight">
\[
  U(\beta) = \sum_{i}\frac{\partial \mu_i'(\beta)}{\partial\beta}V_i({\bf y_i - \mu_i(\beta)})
  \]</div>
</li>
<li><p>Estimate of <span class="math notranslate nohighlight">\(\beta\)</span></p>
<div class="math notranslate nohighlight">
\[
  \hat{\beta} = (\sum_iD_i'V_i^{-1}D_i)^{-1}D_i'V_i^{-1}y_i,
  \]</div>
<p>Where <span class="math notranslate nohighlight">\(D_i = \frac{\partial \mu_i(\beta)}{\partial \beta}\)</span>.</p>
<div class="math notranslate nohighlight">
\[
  \text{Cov}(\hat\beta) = \left(\sum_iD_i'V_i^{-1}D_i\right)^{-1}\left(\sum_iD_i'V_i^{-1}\text{var}(y_i)V_i^{-1}D_i\right)\left(\sum_iD_i'V_i^{-1}D_i\right)^{-1}
  \]</div>
<p>the robust version.</p>
</li>
</ul>
</div>
<div class="section" id="comments-on-gee">
<h5><strong>Comments on GEE</strong><a class="headerlink" href="#comments-on-gee" title="Permalink to this headline">¶</a></h5>
<ul class="simple">
<li><p>GEE is the maximum likelihood score equation for multivariate Gaussian data, and for binary data when <span class="math notranslate nohighlight">\(\text{var}(Y_i)\)</span> is correclty specified.</p></li>
<li><p><span class="math notranslate nohighlight">\(\hat{\beta}\)</span> is consistent when sample size goes to infinity even when <span class="math notranslate nohighlight">\(\text{var}(Y_i)\)</span> is incorrectly specified</p></li>
</ul>
</div>
</div>
</div>
</div>
<div class="section" id="appendix-limitation-of-ols-models-in-analyzing-repeated-measures-data">
<h2>Appendix: Limitation of OLS models in analyzing repeated measures data<a class="headerlink" href="#appendix-limitation-of-ols-models-in-analyzing-repeated-measures-data" title="Permalink to this headline">¶</a></h2>
<p><em>Date: Feb 28, 2014</em></p>
<ul class="simple">
<li><p>One of the most important assumptions for appropriate F-tests when using OLS in repeated measures data is that there is a constant correlation among multiple measure- ments within a subject.</p></li>
<li><p>Some authors have suggested the use of repeated measures MANOVA instead of univariate repeated measures ANOVA when the assumption of constant covari- ance is not met. This is a reasonable approach if there are no missing data. But MANOVA requires that the data for all indi- viduals be available for exactly the same time points to estimate the covariance matrix.</p></li>
<li><p>Algorithms for the computation of variance components using OLS are not optimal when data are missing, even if the assumptions about the covariance structure are correct</p></li>
<li><p><strong>linear mixed models</strong>, which uses an estimation algorithm called <strong>generalized least squares (GLS)</strong> is designed to deal with correlated data.</p></li>
<li><p>Basically, GLS estimates are appropriately weighted based on the covariance structure of the data. The estimates of the variance components are acquired by maximizing either the full likelihood (<em>maximum likelihood, or ML</em>) or a <em>restricted version of the likelihood</em> (restricted or residual maximum likelihood, or REML).</p></li>
<li><p><em>growth curves</em> test for differences in initial values and in rates of growth of each factor’s levels, allowing for a more straightforward interpretation of data. A particular implementation of the growth curve model is called the random coefficients growth curve, where each subject’s parameters are considered a random draw from a population of such parameters. This implementation is also known as multilevel models, or hierarchical linear models.</p></li>
<li><p>The mixed model, although slightly more complicated than the other two structures (requiring the estimation of four rather than two variance components), it is appealing because it is so broadly applicable. We also had some indication from previous work that this structure might be less sensitive to misspecification, and thus more robust in our analyses.</p></li>
<li><p>The determinat of the variance/covariance matrices is a indicator of the variability of the model account for the data.</p></li>
<li><p>Independent random errors can be manipulated to assume any covariance structure by premultiplying the independent variates by some square-root decomposition of the covariance structure. (eg [Cholesky decomposition] (https://en.wikipedia.org/wiki/Cholesky_decomposition))</p></li>
<li><p>The repeated measures OLS algorithm produces accurate F-tests when data are balanced, and quite reasonable results when data are unbalanced and the variance/covariance structure of the data is CS.</p></li>
</ul>
<hr class="footnotes docutils" />
<dl class="footnote brackets">
<dt class="label" id="mmrm-blog"><span class="brackets"><a class="fn-backref" href="#id1">3</a></span></dt>
<dd><p><a class="reference external" href="https://thestatsgeek.com/2021/02/21/mmrm-vs-lme-model/">MMRM vs LME model</a>, <a class="reference external" href="https://thestatsgeek.com/2020/12/30/mixed-model-repeated-measures-mmrm-in-stata-sas-and-r/">Mixed model repeated measures (MMRM) in Stata, SAS and R</a></p>
</dd>
<dt class="label" id="id4"><span class="brackets"><a class="fn-backref" href="#id2">1</a></span></dt>
<dd><p>the convariance structure is usually the nuiance parameter</p>
</dd>
<dt class="label" id="id5"><span class="brackets"><a class="fn-backref" href="#id3">2</a></span></dt>
<dd><p>Two categories of robustness: 1. w.r.t. the outlier; 2. w.r.t. the model assumptions</p>
</dd>
</dl>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./Stats"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>
    <script type="text/javascript">
        function init() {
            WaveDrom.ProcessAll();
        }
        window.onload = init;
    </script>

              </div>
              
            
                <!-- Previous / next buttons -->
<div class='prev-next-area'> 
    <a class='left-prev' id="prev-link" href="Note-Competing_Risk_Regression.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">Competing risk models</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="Note-Cox_PH_model.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">​Cox PH model</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            
        </div>
    </div>
    <footer class="footer">
  <p>
    
      By Ming Yang<br/>
    
        &copy; Copyright 2021.<br/>
  </p>
</footer>
</main>


      </div>
    </div>
  
  <script src="../_static/js/index.be7d3bbb2ef33a8344ce.js"></script>

  </body>
</html>